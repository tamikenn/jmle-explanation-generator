#!/usr/bin/env python3
"""
web_displayã§è¿½åŠ ã•ã‚ŒãŸ150å•ã®è©³ç´°åˆ†æ
"""
import re
from pathlib import Path
from collections import defaultdict

def analyze_added_questions():
    """è¿½åŠ ã•ã‚ŒãŸ150å•ã®è©³ç´°åˆ†æ"""
    print("ğŸ” è¿½åŠ ã•ã‚ŒãŸ150å•ã®è©³ç´°åˆ†æ")
    print("=" * 60)
    
    source_dir = Path("/workspaces/jmle-explanation-generator/raw_data/source_texts")
    
    # 1. å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å•é¡ŒIDæŠ½å‡º
    source_files = sorted([f for f in source_dir.glob("medical_exam_11*.txt") 
                          if "web_display" not in f.name])
    
    all_source_ids = []
    source_by_year = defaultdict(list)
    
    print("ğŸ“ å…ƒãƒ‡ãƒ¼ã‚¿ï¼ˆmedical_exam_11~ï¼‰ã‹ã‚‰å•é¡ŒIDæŠ½å‡º:")
    for file in source_files:
        with open(file, 'r', encoding='utf-8') as f:
            content = f.read()
            pattern = r'\b(\d{3}[A-Z]\d{1,3})\b'
            ids = sorted(set(re.findall(pattern, content)))
            
            all_source_ids.extend(ids)
            for qid in ids:
                year = qid[:3]
                source_by_year[year].append(qid)
            
            print(f"  {file.name}: {len(ids)}å•")
    
    all_source_ids = sorted(set(all_source_ids))
    
    # 2. å®Œæˆå½¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å•é¡ŒIDæŠ½å‡º
    web_file = source_dir / "medical_exam_web_display_final.txt"
    web_ids = []
    web_content = ""
    
    if web_file.exists():
        with open(web_file, 'r', encoding='utf-8') as f:
            web_content = f.read()
            pattern = r'\b(\d{3}[A-Z]\d{1,3})\b'
            web_ids = sorted(set(re.findall(pattern, web_content)))
    
    print(f"\nğŸ“ å®Œæˆå½¢ãƒ‡ãƒ¼ã‚¿ï¼ˆweb_displayï¼‰: {len(web_ids)}å•")
    
    # 3. è¿½åŠ ã•ã‚ŒãŸå•é¡Œã‚’ç‰¹å®š
    added_questions = sorted(set(web_ids) - set(all_source_ids))
    missing_questions = sorted(set(all_source_ids) - set(web_ids))
    
    print(f"\nğŸ” å·®åˆ†åˆ†æ:")
    print(f"  å…ƒãƒ‡ãƒ¼ã‚¿: {len(all_source_ids)}å•")
    print(f"  å®Œæˆå½¢: {len(web_ids)}å•")
    print(f"  è¿½åŠ ã•ã‚ŒãŸå•é¡Œ: {len(added_questions)}å•")
    print(f"  æ¬ è½ã—ãŸå•é¡Œ: {len(missing_questions)}å•")
    
    # 4. è¿½åŠ å•é¡Œã®å¹´åº¦åˆ¥åˆ†æ
    if added_questions:
        print(f"\nğŸ“Š è¿½åŠ å•é¡Œã®å¹´åº¦åˆ¥åˆ†æ:")
        added_by_year = defaultdict(list)
        for qid in added_questions:
            year = qid[:3]
            added_by_year[year].append(qid)
        
        for year in sorted(added_by_year.keys()):
            year_questions = sorted(added_by_year[year])
            print(f"  ç¬¬{year}å›: {len(year_questions)}å•")
            print(f"    å•é¡ŒIDä¾‹: {year_questions[:10]}")
            
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥åˆ†æ
            sections = defaultdict(list)
            for qid in year_questions:
                section = qid[3]
                sections[section].append(qid)
            
            for section in sorted(sections.keys()):
                section_questions = sorted(sections[section])
                print(f"    ã‚»ã‚¯ã‚·ãƒ§ãƒ³{section}: {len(section_questions)}å• {section_questions[:5]}")
    
    # 5. è¿½åŠ å•é¡Œã®å†…å®¹åˆ†æ
    if added_questions and web_content:
        print(f"\nğŸ“ è¿½åŠ å•é¡Œã®å†…å®¹ã‚µãƒ³ãƒ—ãƒ«åˆ†æ:")
        
        sample_count = 0
        for qid in added_questions[:5]:  # æœ€åˆã®5å•ã‚’ã‚µãƒ³ãƒ—ãƒ«åˆ†æ
            # è©²å½“å•é¡Œã®å†…å®¹ã‚’æŠ½å‡º
            pattern = fr'{re.escape(qid)}.*?(?=\d{{3}}[A-Z]\d{{1,3}}|$)'
            match = re.search(pattern, web_content, re.DOTALL)
            
            if match:
                content = match.group(0)
                lines = [line.strip() for line in content.split('\n') if line.strip()]
                
                print(f"\n  ã€å•é¡ŒID: {qid}ã€‘")
                for i, line in enumerate(lines[:10]):  # æœ€åˆã®10è¡Œã‚’è¡¨ç¤º
                    if len(line) > 100:
                        print(f"    {i+1}: {line[:100]}...")
                    else:
                        print(f"    {i+1}: {line}")
                
                sample_count += 1
                if sample_count >= 3:  # æœ€å¤§3å•ã¾ã§
                    break
    
    # 6. å“è³ªè©•ä¾¡æŒ‡æ¨™
    print(f"\nğŸ“ˆ è¿½åŠ å•é¡Œã®å“è³ªè©•ä¾¡:")
    
    if added_questions:
        # å•é¡Œç•ªå·ã®é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯
        for year in sorted(added_by_year.keys()):
            year_questions = sorted(added_by_year[year])
            numbers = []
            for qid in year_questions:
                match = re.search(r'(\d+)$', qid)
                if match:
                    numbers.append(int(match.group(1)))
            
            if numbers:
                numbers = sorted(numbers)
                print(f"  ç¬¬{year}å›:")
                print(f"    ç•ªå·ç¯„å›²: {min(numbers)} - {max(numbers)}")
                
                # é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯
                gaps = []
                for i in range(len(numbers)-1):
                    if numbers[i+1] - numbers[i] > 1:
                        gaps.append((numbers[i], numbers[i+1]))
                
                if gaps:
                    print(f"    ç•ªå·ã®é£›ã³: {gaps[:5]}")
                else:
                    print(f"    ç•ªå·ã®é€£ç¶šæ€§: è‰¯å¥½")
    
    # 7. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    print(f"\nğŸ’¡ è¿½åŠ 150å•ã«é–¢ã™ã‚‹æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    
    if len(added_questions) == 150:
        print("  âœ… äºˆæƒ³é€šã‚Š150å•ãŒè¿½åŠ ã•ã‚Œã¦ã„ã‚‹")
        print("  ğŸ” å„å¹´åº¦30å•ãšã¤ã®å‡ç­‰ãªè¿½åŠ ãƒ‘ã‚¿ãƒ¼ãƒ³")
        print("  ğŸ“ å†…å®¹ã®è©³ç´°ç¢ºèªãŒå¿…è¦")
        
        if missing_questions:
            print(f"  âš ï¸  åŒæ™‚ã«{len(missing_questions)}å•ãŒæ¬ è½ã—ã¦ã„ã‚‹")
            print(f"     æ¬ è½ä¾‹: {missing_questions[:5]}")
        else:
            print("  âœ… å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¬ è½ã—ãŸå•é¡Œã¯ãªã—")
        
        print("\n  ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘")
        print("  1. è¿½åŠ å•é¡Œã®å†…å®¹å“è³ªã‚’è©³ç´°è©•ä¾¡")
        print("  2. åŒ»å­¦çš„å¦¥å½“æ€§ã®ç¢ºèª")
        print("  3. çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®çµ„ã¿è¾¼ã¿åˆ¤æ–­")
    else:
        print(f"  âš ï¸  äºˆæƒ³ã¨ç•°ãªã‚‹è¿½åŠ æ•°: {len(added_questions)}å•")
    
    return {
        'source_ids': all_source_ids,
        'web_ids': web_ids, 
        'added_questions': added_questions,
        'missing_questions': missing_questions,
        'added_by_year': dict(added_by_year)
    }

if __name__ == "__main__":
    analyze_added_questions()