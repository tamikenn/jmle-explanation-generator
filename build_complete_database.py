#!/usr/bin/env python3
"""
æœ€çµ‚ãƒ•ã‚§ãƒ¼ã‚º: 2000å•ã®å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
"""
import re
import csv
import json
from pathlib import Path
from collections import defaultdict
from datetime import datetime

def build_complete_database():
    """2000å•ã®å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰"""
    print("ğŸ—ï¸ å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ï¼ˆæœ€çµ‚ãƒ•ã‚§ãƒ¼ã‚ºï¼‰")
    print("=" * 60)
    
    # ãƒ‘ã‚¹è¨­å®š
    exports_dir = Path("/workspaces/jmle-explanation-generator/raw_data/exports")
    notion_dir = Path("/workspaces/jmle-explanation-generator/raw_data/notion")
    final_dir = Path("/workspaces/jmle-explanation-generator/final_database")
    final_dir.mkdir(exist_ok=True)
    
    # 1. çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    print("\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹èª­ã¿è¾¼ã¿")
    print("-" * 40)
    
    # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    integrated_csv = exports_dir / "integrated_dataset_2000.csv"
    integrated_data = {}
    
    if integrated_csv.exists():
        with open(integrated_csv, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                qid = row['å•é¡ŒID']
                integrated_data[qid] = row
        print(f"  çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(integrated_data)}å•")
    
    # æ—¢å­˜Notionãƒ‡ãƒ¼ã‚¿
    notion_files = list(notion_dir.glob("*.csv"))
    existing_notion = {}
    
    if notion_files:
        with open(notion_files[0], 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                qid = None
                for key in row.keys():
                    if 'å•é¡ŒID' in key:
                        qid = row[key]
                        break
                
                if qid and qid.strip() and re.match(r'\d{3}[A-Z]\d{1,3}', qid.strip()):
                    existing_notion[qid.strip()] = row
        print(f"  æ—¢å­˜Notionãƒ‡ãƒ¼ã‚¿: {len(existing_notion)}å•")
    
    # å¾©å…ƒãƒ‡ãƒ¼ã‚¿
    restore_csv = exports_dir / "notion_missing_questions_restore.csv"
    restore_data = {}
    
    if restore_csv.exists():
        with open(restore_csv, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                qid = None
                for key in row.keys():
                    if 'å•é¡ŒID' in key:
                        qid = row[key]
                        break
                
                if qid and qid.strip():
                    restore_data[qid.strip()] = row
        print(f"  å¾©å…ƒãƒ‡ãƒ¼ã‚¿: {len(restore_data)}å•")
    
    # 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆ
    print("\nğŸ”— ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆ")
    print("-" * 40)
    
    complete_database = {}
    
    # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å…¨å•é¡Œã‚’åŸºæº–ã¨ã™ã‚‹
    for qid in sorted(integrated_data.keys()):
        # åŸºæœ¬æƒ…å ±
        integrated_row = integrated_data[qid]
        
        # å®Œå…¨ãªè¨˜éŒ²ä½œæˆ
        complete_record = {
            'å•é¡ŒID': qid,
            'å¹´åº¦': qid[:3],
            'ã‚»ã‚¯ã‚·ãƒ§ãƒ³': qid[3],
            'å•é¡Œç•ªå·': qid[4:],
            'ã‚½ãƒ¼ã‚¹': integrated_row.get('ã‚½ãƒ¼ã‚¹', ''),
            'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„': integrated_row.get('ã‚³ãƒ³ãƒ†ãƒ³ãƒ„', ''),
            'ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹': 'complete'
        }
        
        # Notionã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯çµ±åˆ
        if qid in existing_notion:
            notion_row = existing_notion[qid]
            complete_record['æ­£ç­”'] = notion_row.get('æ­£ç­”', '')
            complete_record['æ­£ç­”ç‡'] = notion_row.get('æ­£ç­”ç‡', '')
            complete_record['è‹±èªå•é¡Œ'] = notion_row.get('è‹±èªå•é¡Œ', 'No')
            complete_record['ç”»åƒå•é¡Œ'] = notion_row.get('ç”»åƒå•é¡Œ', 'No')
            complete_record['é€£å•'] = notion_row.get('é€£å•', 'No')
            complete_record['è¨ˆç®—å•é¡Œ'] = notion_row.get('è¨ˆç®—å•é¡Œ', 'No')
            complete_record['å•é¡Œæ–‡'] = notion_row.get('å•é¡Œæ–‡', '')
            complete_record['ç—‡ä¾‹æ–‡'] = notion_row.get('ç—‡ä¾‹æ–‡', '')
            complete_record['é¸æŠè‚¢'] = notion_row.get('é¸æŠè‚¢', '')
            complete_record['Webè¡¨ç¤ºç”¨'] = notion_row.get('Webè¡¨ç¤ºç”¨', '')
            complete_record['ã‚¿ã‚°'] = notion_row.get('ã‚¿ã‚°', '')
            complete_record['æœ€çµ‚æ›´æ–°'] = notion_row.get('æœ€çµ‚æ›´æ–°', '')\n            complete_record['ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹'] = 'notion_existing'\n        elif qid in restore_data:\n            restore_row = restore_data[qid]\n            complete_record['æ­£ç­”'] = restore_row.get('æ­£ç­”', '')\n            complete_record['æ­£ç­”ç‡'] = restore_row.get('æ­£ç­”ç‡', '')\n            complete_record['è‹±èªå•é¡Œ'] = restore_row.get('è‹±èªå•é¡Œ', 'No')\n            complete_record['ç”»åƒå•é¡Œ'] = restore_row.get('ç”»åƒå•é¡Œ', 'No')\n            complete_record['é€£å•'] = restore_row.get('é€£å•', 'No')\n            complete_record['è¨ˆç®—å•é¡Œ'] = restore_row.get('è¨ˆç®—å•é¡Œ', 'No')\n            complete_record['å•é¡Œæ–‡'] = restore_row.get('å•é¡Œæ–‡', '')\n            complete_record['ç—‡ä¾‹æ–‡'] = restore_row.get('ç—‡ä¾‹æ–‡', '')\n            complete_record['é¸æŠè‚¢'] = restore_row.get('é¸æŠè‚¢', '')\n            complete_record['Webè¡¨ç¤ºç”¨'] = restore_row.get('Webè¡¨ç¤ºç”¨', complete_record['ã‚³ãƒ³ãƒ†ãƒ³ãƒ„'])\n            complete_record['ã‚¿ã‚°'] = restore_row.get('ã‚¿ã‚°', '')\n            complete_record['æœ€çµ‚æ›´æ–°'] = restore_row.get('æœ€çµ‚æ›´æ–°', '')\n            complete_record['ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹'] = 'restored'\n        else:\n            # åŸºæœ¬ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§åŸ‹ã‚ã‚‹\n            complete_record['æ­£ç­”'] = ''\n            complete_record['æ­£ç­”ç‡'] = ''\n            complete_record['è‹±èªå•é¡Œ'] = 'No'\n            complete_record['ç”»åƒå•é¡Œ'] = 'No'\n            complete_record['é€£å•'] = 'No'\n            complete_record['è¨ˆç®—å•é¡Œ'] = 'No'\n            complete_record['å•é¡Œæ–‡'] = ''\n            complete_record['ç—‡ä¾‹æ–‡'] = ''\n            complete_record['é¸æŠè‚¢'] = ''\n            complete_record['Webè¡¨ç¤ºç”¨'] = complete_record['ã‚³ãƒ³ãƒ†ãƒ³ãƒ„']\n            complete_record['ã‚¿ã‚°'] = ''\n            complete_record['æœ€çµ‚æ›´æ–°'] = ''\n            complete_record['ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹'] = 'basic_only'\n        \n        complete_database[qid] = complete_record\n    \n    print(f\"  å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰å®Œäº†: {len(complete_database)}å•\")\n    \n    # 3. å“è³ªæ¤œè¨¼\n    print(\"\\nâœ… ã‚¹ãƒ†ãƒƒãƒ—3: å“è³ªæ¤œè¨¼\")\n    print(\"-\" * 40)\n    \n    # ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ\n    state_counts = defaultdict(int)\n    for record in complete_database.values():\n        state_counts[record['ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹']] += 1\n    \n    print(\"  ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹åˆ¥å†…è¨³:\")\n    for state, count in state_counts.items():\n        print(f\"    {state}: {count}å•\")\n    \n    # å¹´åº¦åˆ¥æ¤œè¨¼\n    by_year = defaultdict(list)\n    for qid, record in complete_database.items():\n        by_year[record['å¹´åº¦']].append(qid)\n    \n    print(\"\\n  å¹´åº¦åˆ¥æ¤œè¨¼:\")\n    for year in sorted(by_year.keys()):\n        print(f\"    ç¬¬{year}å›: {len(by_year[year])}å•\")\n        \n        if len(by_year[year]) != 400:\n            print(f\"      âš ï¸  äºˆæƒ³ã¨ç•°ãªã‚‹å•é¡Œæ•°\")\n    \n    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥æ¤œè¨¼\n    by_section = defaultdict(list)\n    for qid, record in complete_database.items():\n        by_section[record['ã‚»ã‚¯ã‚·ãƒ§ãƒ³']].append(qid)\n    \n    print(\"\\n  ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥æ¤œè¨¼:\")\n    for section in sorted(by_section.keys()):\n        print(f\"    ã‚»ã‚¯ã‚·ãƒ§ãƒ³{section}: {len(by_section[section])}å•\")\n    \n    # 4. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n    print(\"\\nğŸ’¾ ã‚¹ãƒ†ãƒƒãƒ—4: æœ€çµ‚å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\")\n    print(\"-\" * 40)\n    \n    # CSVå½¢å¼ï¼ˆå®Œå…¨ç‰ˆï¼‰\n    final_csv = final_dir / \"complete_medical_exam_database_2000.csv\"\n    \n    fieldnames = ['å•é¡ŒID', 'å¹´åº¦', 'ã‚»ã‚¯ã‚·ãƒ§ãƒ³', 'å•é¡Œç•ªå·', 'æ­£ç­”', 'æ­£ç­”ç‡',\n                  'è‹±èªå•é¡Œ', 'ç”»åƒå•é¡Œ', 'é€£å•', 'è¨ˆç®—å•é¡Œ', 'å•é¡Œæ–‡', 'ç—‡ä¾‹æ–‡',\n                  'é¸æŠè‚¢', 'Webè¡¨ç¤ºç”¨', 'ã‚¿ã‚°', 'æœ€çµ‚æ›´æ–°', 'ã‚½ãƒ¼ã‚¹', 'ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹']\n    \n    with open(final_csv, 'w', newline='', encoding='utf-8') as f:\n        writer = csv.DictWriter(f, fieldnames=fieldnames)\n        writer.writeheader()\n        \n        for qid in sorted(complete_database.keys()):\n            writer.writerow(complete_database[qid])\n    \n    print(f\"  å®Œå…¨ç‰ˆCSV: {final_csv}\")\n    \n    # JSONå½¢å¼ï¼ˆæ§‹é€ åŒ–ï¼‰\n    final_json = final_dir / \"complete_medical_exam_database_2000.json\"\n    \n    json_data = {\n        'metadata': {\n            'total_questions': len(complete_database),\n            'creation_date': datetime.now().isoformat(),\n            'version': '1.0',\n            'description': 'æ—¥æœ¬åŒ»å¸«å›½å®¶è©¦é¨“å•é¡Œå®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆç¬¬115-119å›ï¼‰'\n        },\n        'statistics': {\n            'by_year': {year: len(questions) for year, questions in by_year.items()},\n            'by_section': {section: len(questions) for section, questions in by_section.items()},\n            'by_data_state': dict(state_counts)\n        },\n        'questions': complete_database\n    }\n    \n    with open(final_json, 'w', encoding='utf-8') as f:\n        json.dump(json_data, f, ensure_ascii=False, indent=2)\n    \n    print(f\"  JSONå½¢å¼: {final_json}\")\n    \n    # çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ\n    stats_file = final_dir / \"database_statistics.md\"\n    \n    with open(stats_file, 'w', encoding='utf-8') as f:\n        f.write(\"# å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ\\n\\n\")\n        f.write(f\"## åŸºæœ¬æƒ…å ±\\n\")\n        f.write(f\"- ç·å•é¡Œæ•°: {len(complete_database)}å•\\n\")\n        f.write(f\"- å¯¾è±¡å¹´åº¦: ç¬¬115-119å›åŒ»å¸«å›½å®¶è©¦é¨“\\n\")\n        f.write(f\"- ä½œæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n        \n        f.write(\"## å¹´åº¦åˆ¥å†…è¨³\\n\")\n        for year in sorted(by_year.keys()):\n            f.write(f\"- ç¬¬{year}å›: {len(by_year[year])}å•\\n\")\n        \n        f.write(\"\\n## ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥å†…è¨³\\n\")\n        for section in sorted(by_section.keys()):\n            f.write(f\"- ã‚»ã‚¯ã‚·ãƒ§ãƒ³{section}: {len(by_section[section])}å•\\n\")\n        \n        f.write(\"\\n## ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹åˆ¥å†…è¨³\\n\")\n        for state, count in state_counts.items():\n            f.write(f\"- {state}: {count}å•\\n\")\n        \n        f.write(\"\\n## å¾©å…ƒæˆåŠŸç‡\\n\")\n        total = len(complete_database)\n        complete_data = state_counts['notion_existing'] + state_counts['restored']\n        f.write(f\"å®Œå…¨ãƒ‡ãƒ¼ã‚¿: {complete_data}/{total}å• ({complete_data/total*100:.1f}%)\\n\")\n    \n    print(f\"  çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ: {stats_file}\")\n    \n    # 5. æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ\n    print(\"\\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—5: æœ€çµ‚æ¤œè¨¼\")\n    print(\"-\" * 40)\n    \n    total_questions = len(complete_database)\n    complete_data_count = state_counts['notion_existing'] + state_counts['restored']\n    \n    print(f\"  âœ… ç·å•é¡Œæ•°: {total_questions}å•\")\n    print(f\"  ğŸ“Š å®Œå…¨ãƒ‡ãƒ¼ã‚¿: {complete_data_count}å• ({complete_data_count/total_questions*100:.1f}%)\")\n    print(f\"  ğŸ”„ å¾©å…ƒãƒ‡ãƒ¼ã‚¿: {state_counts['restored']}å•\")\n    print(f\"  ğŸ’¾ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {state_counts['notion_existing']}å•\")\n    \n    if total_questions == 2000:\n        print(\"  ğŸ¯ ç›®æ¨™é”æˆ: 2000å•ã®å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰æˆåŠŸï¼\")\n    \n    # 6. æœ€çµ‚ã‚µãƒãƒªãƒ¼\n    print(\"\\nğŸ‰ ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†\")\n    print(\"-\" * 40)\n    \n    print(\"  ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:\")\n    print(f\"     - {final_csv.name} (CSVå®Œå…¨ç‰ˆ)\")\n    print(f\"     - {final_json.name} (JSONæ§‹é€ åŒ–ç‰ˆ)\")\n    print(f\"     - {stats_file.name} (çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ)\")\n    \n    print(\"\\n  ğŸš€ JMLEèª¬æ˜æ–‡ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†\")\n    print(\"     - 2000å•ã®åŒ»å¸«å›½å®¶è©¦é¨“ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹\")\n    print(\"     - å®Œå…¨ãªå•é¡Œæ§‹é€ ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿\")\n    print(\"     - èª¬æ˜æ–‡ç”Ÿæˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåŸºç›¤\")\n    \n    return {\n        'total_questions': total_questions,\n        'complete_data_count': complete_data_count,\n        'success_rate': complete_data_count / total_questions,\n        'output_files': [final_csv, final_json, stats_file]\n    }\n\nif __name__ == \"__main__\":\n    build_complete_database()